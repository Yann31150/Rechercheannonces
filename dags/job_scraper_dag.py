"""
DAG Airflow pour le scraping quotidien des offres d'emploi
ExÃ©cute le scraping tous les jours Ã  10h00 et envoie un email avec les nouvelles annonces
"""
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
import sys
import os

# Ajouter le rÃ©pertoire parent au path pour importer les modules
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scrape_jobs_airflow import run_daily_scraping
from compare_jobs import get_new_jobs
from email_notifier import send_email
from utils import print_info, print_success, print_error


def scrape_jobs_task(**context):
    """TÃ¢che de scraping"""
    print_info("ðŸš€ DÃ©marrage de la tÃ¢che de scraping...")
    success, message, count = run_daily_scraping()
    
    if success:
        print_success(f"âœ… Scraping terminÃ©: {message}")
        # Passer le nombre d'offres au contexte pour la tÃ¢che suivante
        context['ti'].xcom_push(key='jobs_count', value=count)
        return {'status': 'success', 'jobs_count': count, 'message': message}
    else:
        print_error(f"âŒ Scraping Ã©chouÃ©: {message}")
        raise Exception(f"Scraping Ã©chouÃ©: {message}")


def compare_and_notify_task(**context):
    """TÃ¢che de comparaison et envoi d'email"""
    print_info("ðŸ“Š Comparaison des nouvelles offres...")
    
    try:
        # RÃ©cupÃ©rer les nouvelles offres
        new_jobs, all_jobs = get_new_jobs()
        
        jobs_count = len(all_jobs)
        new_jobs_count = len(new_jobs)
        
        print_info(f"ðŸ“ˆ Total: {jobs_count} offres")
        print_info(f"ðŸ†• Nouvelles: {new_jobs_count} offres")
        
        # Toujours envoyer un email, mÃªme s'il n'y a pas de nouvelles offres
        # (pour confirmer que le scraping a fonctionnÃ©)
        print_info("ðŸ“§ Envoi de l'email de notification...")
        email_sent = send_email(new_jobs, jobs_count)
        
        if email_sent:
            print_success(f"âœ… Email envoyÃ© avec {new_jobs_count} nouvelles offres")
            return {
                'status': 'success',
                'total_jobs': jobs_count,
                'new_jobs': new_jobs_count,
                'email_sent': True
            }
        else:
            print_error("âŒ Ã‰chec de l'envoi de l'email")
            return {
                'status': 'warning',
                'total_jobs': jobs_count,
                'new_jobs': new_jobs_count,
                'email_sent': False
            }
            
    except Exception as e:
        error_msg = f"Erreur lors de la comparaison/notification: {str(e)}"
        print_error(error_msg)
        raise Exception(error_msg)


# DÃ©finition du DAG
default_args = {
    'owner': 'job_scraper',
    'depends_on_past': False,
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
    'start_date': datetime(2024, 1, 1),
}

dag = DAG(
    'daily_job_scraper',
    default_args=default_args,
    description='Scraping quotidien des offres d\'emploi Data et envoi d\'alertes par email',
    schedule_interval='0 10 * * *',  # Tous les jours Ã  10h00
    catchup=False,
    tags=['scraping', 'jobs', 'data', 'email'],
)

# TÃ¢che 1: Scraping
scrape_task = PythonOperator(
    task_id='scrape_all_sites',
    python_callable=scrape_jobs_task,
    dag=dag,
)

# TÃ¢che 2: Comparaison et notification
notify_task = PythonOperator(
    task_id='compare_and_notify',
    python_callable=compare_and_notify_task,
    dag=dag,
)

# DÃ©finir l'ordre d'exÃ©cution
scrape_task >> notify_task

