# ğŸ—ï¸ Architecture du SystÃ¨me

## ğŸ“‹ Vue d'ensemble

Le systÃ¨me est composÃ© de **2 parties principales** :

### 1. ğŸ” SCRAPING (Recherche d'annonces)
**Fichier :** `main_unified.py` + scrapers individuels  
**Lancement :** `ğŸ” Recherche d'emploi.command` sur le bureau  
**Fonction :** Scrape les offres d'emploi sur tous les sites

### 2. ğŸ“Š APPLICATION STREAMLIT (Visualisation + Candidatures + Suivi)
**Fichier :** `app_unified.py`  
**Lancement :** `ğŸ¯ Application ComplÃ¨te.command` sur le bureau  
**Fonction :** Visualiser, prÃ©parer candidatures, suivre

---

## ğŸ” PARTIE 1 : SCRAPING DES ANNONCES

### Scripts disponibles
- **`main_unified.py`** : Recherche sur TOUS les sites (LinkedIn, WTTJ, Indeed, APEC, etc.)
- **`main.py`** : Recherche LinkedIn uniquement
- **`scraper.py`** : Scraper LinkedIn
- **`scraper_wttj.py`** : Scraper Welcome to the Jungle
- **`scraper_indeed.py`** : Scraper Indeed
- **`scraper_apec.py`** : Scraper APEC
- **`scraper_helloworks.py`** : Scraper Helloworks
- **`scraper_freework.py`** : Scraper Free-Work
- **`scraper_bonne_alternance.py`** : Scraper La Bonne Alternance

### Comment lancer
1. **Depuis le bureau** : Double-clic sur `ğŸ” Recherche d'emploi.command`
2. **En ligne de commande** :
   ```bash
   python main_unified.py --search "Data Scientist" --location "Haute-Garonne, France"
   ```

### RÃ©sultat
- Sauvegarde dans `data/jobs.json`
- Copie automatique dans `~/Desktop/Annonces/`
- Export CSV/Excel optionnel

---

## ğŸ“Š PARTIE 2 : APPLICATION STREAMLIT

### Fichier principal
- **`app_unified.py`** : Application complÃ¨te avec tous les onglets

### FonctionnalitÃ©s

#### Onglet 1 : ğŸ“‹ Offres d'emploi
- Visualiser toutes les offres scrapÃ©es
- Filtres : titre, entreprise, source, localisation, statut candidature
- Tri par date (plus rÃ©cent en premier)
- Bouton "PrÃ©parer candidature" directement depuis la liste

#### Onglet 2 : ğŸ“ PrÃ©parer candidatures
- SÃ©lection d'offres pour prÃ©parer des candidatures
- GÃ©nÃ©ration automatique de lettres avec LLM (Ollama)
- Utilise le contenu du CV pour personnaliser

#### Onglet 3 : ğŸ“¤ Candidatures prÃ©parÃ©es
- Liste des candidatures prÃªtes Ã  envoyer
- Visualisation des lettres gÃ©nÃ©rÃ©es
- Marquer comme envoyÃ©e

#### Onglet 4 : ğŸ“Š Suivi complet
- Toutes vos candidatures avec statuts
- Filtres par statut et entreprise
- Notes personnalisÃ©es pour chaque candidature
- Mise Ã  jour du statut (prÃ©parÃ©e â†’ envoyÃ©e â†’ acceptÃ©e/refusÃ©e)
- TÃ©lÃ©chargement des lettres

#### Onglet 5 : ğŸ“ˆ Statistiques
- Graphiques des offres par source
- Top entreprises
- Statistiques de candidatures

#### Onglet 6 : âš™ï¸ Configuration
- Modifier informations personnelles
- Chemin vers CV
- VÃ©rification Ollama

### Comment lancer
1. **Depuis le bureau** : Double-clic sur `ğŸ¯ Application ComplÃ¨te.command`
2. **En ligne de commande** :
   ```bash
   streamlit run app_unified.py
   ```

---

## ğŸ”„ Flux de travail recommandÃ©

```
1. SCRAPING
   â†“
   [Double-clic sur ğŸ” Recherche d'emploi.command]
   â†“
   [Scraping sur tous les sites]
   â†“
   [Sauvegarde dans data/jobs.json]
   â†“
   âœ… Offres disponibles

2. VISUALISATION & CANDIDATURES
   â†“
   [Double-clic sur ğŸ¯ Application ComplÃ¨te.command]
   â†“
   [Onglet "Offres d'emploi" : Voir les offres]
   â†“
   [Onglet "PrÃ©parer candidatures" : GÃ©nÃ©rer lettres]
   â†“
   [Onglet "Suivi complet" : Suivre les candidatures]
   â†“
   âœ… Candidatures prÃ©parÃ©es et suivies
```

---

## ğŸ“ Fichiers clÃ©s

### DonnÃ©es
- **`data/jobs.json`** : Toutes les offres scrapÃ©es (utilisÃ© par les deux parties)
- **`data/applications.json`** : Toutes les candidatures (utilisÃ© par l'app Streamlit)
- **`cover_letters/`** : Lettres de motivation gÃ©nÃ©rÃ©es
- **`personal_info.json`** : Vos informations personnelles

### Scripts
- **`main_unified.py`** : Script de scraping principal
- **`app_unified.py`** : Application Streamlit complÃ¨te
- **`application_manager.py`** : Gestion des candidatures
- **`cover_letter_generator.py`** : GÃ©nÃ©ration de lettres
- **`llm_generator.py`** : Interface avec les LLM (Ollama, etc.)

---

## âœ… RÃ©sumÃ©

**2 parties distinctes :**

1. **ğŸ” SCRAPING** â†’ `ğŸ” Recherche d'emploi.command`
   - Scrape les annonces
   - Sauvegarde dans `data/jobs.json`

2. **ğŸ“Š APPLICATION** â†’ `ğŸ¯ Application ComplÃ¨te.command`
   - Visualise les annonces
   - PrÃ©pare les candidatures
   - Assure le suivi

**Tout est connectÃ© via `data/jobs.json` !**

